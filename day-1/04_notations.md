## üß† **What are Asymptotic Notations?**

> **Asymptotic Notations** are **mathematical tools** used to describe the **efficiency of an algorithm** when the input size (**n**) becomes very large.

In other words:

> They tell us **how fast or slow an algorithm grows** as the input size increases.

---

### ‚öôÔ∏è **Why we use them:**

When analyzing an algorithm, we don‚Äôt care about:

* exact seconds,
* hardware, or
* language used.

We only care about **how performance scales** when input grows (e.g., from 10 to 1 million).

---

### üß© **Example:**

Two algorithms for the same problem:

| Input Size (n) | Algo A (2n + 3 steps) | Algo B (5n¬≤ + 2 steps) |
| -------------- | --------------------- | ---------------------- |
| 10             | 23                    | 502                    |
| 100            | 203                   | 50,002                 |

When **n** grows, **n¬≤** grows much faster than **n**,
so Algo A is more efficient for large inputs.

‚û° We use **asymptotic notations** to describe this mathematically.

---

## üìä **Types of Asymptotic Notations**

There are **three main notations**:

| Symbol      | Name                   | Describes                               | Think of it as       |
| ----------- | ---------------------- | --------------------------------------- | -------------------- |
| **O(f(n))** | **Big O Notation**     | **Upper bound (worst case)**            | "At most this fast"  |
| **Œ©(f(n))** | **Big Omega Notation** | **Lower bound (best case)**             | "At least this fast" |
| **Œò(f(n))** | **Theta Notation**     | **Tight bound (average/expected case)** | "Exactly this fast"  |

---

## üîπ 1. **Big O Notation ‚Äì Upper Bound (Worst Case)**

**Definition:**

> Big O gives the **maximum time** an algorithm can take to complete for an input size **n**.

It shows the **worst-case scenario** ‚Äî the slowest the algorithm could ever be.

---

### üßÆ Example:

If an algorithm takes
**T(n) = 3n¬≤ + 4n + 2**,
then the **Big O notation** is:

üëâ **O(n¬≤)**

Because when **n** becomes very large,
**n¬≤** dominates (the smaller terms become negligible).

---

### üí¨ Real-life analogy:

> ‚ÄúIt will take **at most** 1 hour to finish.‚Äù
> That‚Äôs **Big O** ‚Äî the worst-case guarantee.

---

### üìå Common Big O complexities:

| Complexity     | Name          | Example                                   |
| -------------- | ------------- | ----------------------------------------- |
| **O(1)**       | Constant time | Accessing an array element                |
| **O(log n)**   | Logarithmic   | Binary Search                             |
| **O(n)**       | Linear        | Linear Search                             |
| **O(n log n)** | Log-linear    | Merge Sort, Quick Sort                    |
| **O(n¬≤)**      | Quadratic     | Bubble Sort                               |
| **O(2‚Åø)**      | Exponential   | Recursive Fibonacci                       |
| **O(n!)**      | Factorial     | Travelling Salesman Problem (Brute Force) |

---

## üîπ 2. **Big Omega (Œ©) Notation ‚Äì Lower Bound (Best Case)**

**Definition:**

> Big Œ© gives the **minimum time** an algorithm will take ‚Äî
> the **best-case scenario**.

---

### üßÆ Example:

If **T(n) = 3n¬≤ + 4n + 2**,
then **Œ©(n¬≤)** means:

> The algorithm takes **at least proportional to n¬≤** steps.

---

### üí¨ Real-life analogy:

> ‚ÄúIt will take **at least** 30 minutes to finish.‚Äù
> That‚Äôs **Big Omega** ‚Äî the best-case limit.

---

## üîπ 3. **Theta (Œò) Notation ‚Äì Tight Bound (Average Case)**

**Definition:**

> Big Œò gives both the **upper and lower bound** of an algorithm ‚Äî
> meaning it grows **exactly at that rate**.

If the time complexity is between two functions that both grow like **n¬≤**,
then we say it‚Äôs **Œò(n¬≤)**.

---

### üßÆ Example:

If **T(n) = 3n¬≤ + 4n + 2**,
then **Œò(n¬≤)** because both upper and lower bounds are proportional to **n¬≤**.

---

### üí¨ Real-life analogy:

> ‚ÄúIt will take **around 45 minutes**, no matter what.‚Äù
> That‚Äôs **Theta** ‚Äî the typical or average growth rate.

---

## ‚öñÔ∏è **Comparison Summary Table:**

| Notation    | Meaning     | Describes              | Example Statement                         |
| ----------- | ----------- | ---------------------- | ----------------------------------------- |
| **O(f(n))** | Upper Bound | **Worst case**         | Algorithm takes *at most* f(n) time       |
| **Œ©(f(n))** | Lower Bound | **Best case**          | Algorithm takes *at least* f(n) time      |
| **Œò(f(n))** | Tight Bound | **Average/Exact case** | Algorithm takes *approximately* f(n) time |

---

### üßÆ **Example Summary: Linear Search**

Searching for an element in an array of size **n**:

| Case             | Description                               | Notation |
| ---------------- | ----------------------------------------- | -------- |
| **Best case**    | Element is first ‚Üí 1 comparison           | **Œ©(1)** |
| **Worst case**   | Element not found or last ‚Üí n comparisons | **O(n)** |
| **Average case** | Element somewhere in middle               | **Œò(n)** |

---

## üß© **In Short:**

| Notation    | Meaning     | Think as             |
| ----------- | ----------- | -------------------- |
| **O(f(n))** | Upper bound | Worst case           |
| **Œ©(f(n))** | Lower bound | Best case            |
| **Œò(f(n))** | Tight bound | Average / Exact case |
